# API & Developer Documentation

Comprehensive reference for the AI NeuralWarden Pipeline internals — data models, agents, rule engine, pipeline orchestration, CLI, and Gradio dashboard.

---

## Table of Contents

- [Data Models](#data-models)
  - [LogEntry](#logentry)
  - [Threat](#threat)
  - [ClassifiedThreat](#classifiedthreat)
  - [ActionStep](#actionstep)
  - [IncidentReport](#incidentreport)
- [Pipeline State](#pipeline-state)
- [Rule-Based Detection](#rule-based-detection)
- [Agents](#agents)
  - [Ingest Agent (Haiku 4.5)](#ingest-agent)
  - [Detect Agent (Sonnet 4.5)](#detect-agent)
  - [Classify Agent (Sonnet 4.5)](#classify-agent)
  - [Report Agent (Opus 4.6)](#report-agent)
- [Pipeline Orchestration](#pipeline-orchestration)
- [CLI Reference](#cli-reference)
- [Gradio Dashboard](#gradio-dashboard)
- [Error Handling & Fallbacks](#error-handling--fallbacks)
- [Sample Log Formats](#sample-log-formats)
- [Testing](#testing)
- [Cost Model](#cost-model)

---

## Data Models

All models use [Pydantic v2](https://docs.pydantic.dev/) `BaseModel` with field validation.

### LogEntry

**File:** `models/log_entry.py`

A single parsed security log entry produced by the Ingest Agent.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `index` | `int` | *required* | Original line index in raw input |
| `timestamp` | `str` | `""` | Normalized timestamp string |
| `source` | `str` | `""` | Log source (e.g., `sshd`, `sudo`, `scp`) |
| `event_type` | `str` | `"unknown"` | One of: `failed_auth`, `successful_auth`, `file_transfer`, `data_transfer`, `command_exec`, `connection`, `privilege_escalation`, `system`, `unknown` |
| `source_ip` | `str` | `""` | Source IP address |
| `dest_ip` | `str` | `""` | Destination IP address |
| `user` | `str` | `""` | Username involved |
| `details` | `str` | `""` | Additional parsed details |
| `raw_text` | `str` | *required* | Original raw log line |
| `is_valid` | `bool` | `True` | Whether parsing succeeded |
| `parse_error` | `str \| None` | `None` | Error message if parsing failed |

### Threat

**File:** `models/threat.py`

A detected security threat before risk classification.

| Field | Type | Constraints | Description |
|-------|------|-------------|-------------|
| `threat_id` | `str` | *required* | Unique ID (e.g., `RULE-BRUTE-001`, `AI-RECON-001`) |
| `type` | `str` | *required* | Threat type: `brute_force`, `port_scan`, `privilege_escalation`, `data_exfiltration`, `lateral_movement`, `reconnaissance`, `c2_communication`, `suspicious_activity` |
| `confidence` | `float` | `0.0–1.0` | Detection confidence score |
| `source_log_indices` | `list[int]` | — | Indices of triggering log entries |
| `method` | `Literal["rule_based", "ai_detected"]` | *required* | Detection method used |
| `description` | `str` | *required* | Human-readable description |
| `source_ip` | `str` | `""` | Primary source IP |

### ClassifiedThreat

**File:** `models/threat.py`

A threat enriched with risk scoring and MITRE ATT&CK mapping. Contains all `Threat` fields plus:

| Field | Type | Constraints | Description |
|-------|------|-------------|-------------|
| `risk` | `Literal` | `critical\|high\|medium\|low\|informational` | Severity level |
| `risk_score` | `float` | `0.0–10.0` | Numeric score (likelihood × impact × exploitability) |
| `mitre_technique` | `str` | — | MITRE ATT&CK technique ID (e.g., `T1110`) |
| `mitre_tactic` | `str` | — | MITRE ATT&CK tactic (e.g., `Initial Access`) |
| `business_impact` | `str` | — | Business impact assessment |
| `affected_systems` | `list[str]` | — | Systems affected |
| `remediation_priority` | `int` | `≥ 0` | Priority ranking (1 = highest) |

### ActionStep

**File:** `models/incident_report.py`

A single remediation action in the incident report.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `step` | `int` | *required* | Step number |
| `action` | `str` | *required* | Specific action to take |
| `urgency` | `str` | *required* | `immediate`, `1hr`, `24hr`, `1week` |
| `owner` | `str` | `"Security Team"` | Responsible party |

### IncidentReport

**File:** `models/incident_report.py`

Complete incident report generated by the Report Agent.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `summary` | `str` | *required* | Executive summary (2–3 sentences) |
| `threat_count` | `int` | `0` | Total threats detected |
| `critical_count` | `int` | `0` | Critical-severity threats |
| `high_count` | `int` | `0` | High-severity threats |
| `medium_count` | `int` | `0` | Medium-severity threats |
| `low_count` | `int` | `0` | Low-severity threats |
| `timeline` | `str` | `""` | Reconstructed attack timeline |
| `action_plan` | `list[ActionStep]` | `[]` | Ordered remediation steps |
| `recommendations` | `list[str]` | `[]` | Strategic prevention recommendations |
| `ioc_summary` | `list[str]` | `[]` | Indicators of Compromise |
| `mitre_techniques` | `list[str]` | `[]` | All MITRE ATT&CK technique IDs observed |
| `generated_at` | `datetime` | `now()` | Report generation timestamp |

---

## Pipeline State

**File:** `pipeline/state.py`

`PipelineState` is a `TypedDict(total=False)` that flows through the LangGraph pipeline. Each agent reads what it needs and writes its outputs.

```
┌──────────────────────────────────────────────────────┐
│                   PipelineState                      │
├──────────────────────────────────────────────────────┤
│ Input         │ raw_logs: list[str]                  │
├───────────────┼──────────────────────────────────────┤
│ Ingest writes │ parsed_logs: list[LogEntry]          │
│               │ invalid_count: int                   │
│               │ total_count: int                     │
├───────────────┼──────────────────────────────────────┤
│ Detect writes │ threats: list[Threat]                │
│               │ detection_stats: dict[str, Any]      │
├───────────────┼──────────────────────────────────────┤
│ Classify      │ classified_threats: list[Classified] │
├───────────────┼──────────────────────────────────────┤
│ Report writes │ report: IncidentReport | None        │
├───────────────┼──────────────────────────────────────┤
│ Metadata      │ error: str | None                    │
│               │ pipeline_cost: float                 │
│               │ pipeline_time: float                 │
└──────────────────────────────────────────────────────┘
```

---

## Rule-Based Detection

**File:** `rules/detection.py`

Five pattern-matching detectors that run **instantly with zero API cost**. These always execute before AI detection.

### `detect_brute_force(logs, threshold=5)`

Detects N+ failed authentication attempts from the same IP.

- **Matches:** `event_type == "failed_auth"` with same `source_ip`
- **Confidence:** `min(0.5 + count × 0.05, 0.99)`
- **Threat ID:** `RULE-BRUTE-{ip}`

### `detect_port_scan(logs, threshold=10)`

Detects connections to N+ distinct ports from the same source.

- **Matches:** `event_type == "connection"` with port in `details`
- **Confidence:** `min(0.6 + ports × 0.03, 0.95)`
- **Threat ID:** `RULE-SCAN-{ip}`

### `detect_privilege_escalation(logs)`

Detects sudo/su usage patterns.

- **Matches:** `event_type in (privilege_escalation, sudo, su)` or `source in (sudo, su)` or `"USER=root"` in raw text
- **Confidence:** `0.85` (fixed)
- **Threat ID:** `RULE-PRIVESC-001`

### `detect_data_exfiltration(logs, threshold_mb=100.0)`

Detects large outbound transfers exceeding threshold.

- **Matches:** `event_type in (file_transfer, data_transfer)` with size in raw text
- **Size parsing:** Supports GB, MB, KB units
- **Confidence:** `min(0.7 + (total_mb / 1000) × 0.1, 0.95)`
- **Threat ID:** `RULE-EXFIL-001`

### `detect_lateral_movement(logs)`

Detects internal-to-internal connections on unusual ports.

- **Matches:** Both `source_ip` and `dest_ip` are RFC 1918 addresses (`10.x`, `172.16-31.x`, `192.168.x`) with `event_type in (connection, ssh, rdp, smb)`
- **Confidence:** `0.75` (fixed)
- **Threat ID:** `RULE-LATERAL-001`

### `run_all_rules(logs)`

Aggregator that runs all five detectors and returns combined `list[Threat]`.

---

## Agents

### Ingest Agent

**File:** `pipeline/agents/ingest.py`
**Model:** Claude Haiku 4.5 (`claude-haiku-4-5-20251001`) — $0.25/MTok
**Temperature:** 0

Parses raw log lines into structured `LogEntry` objects via batch prompting.

**Function:** `run_ingest(state: PipelineState) -> dict`

**Behavior:**
1. Numbers all raw log lines as `[0] line text...`
2. Sends batch to Haiku with JSON-mode system prompt
3. Parses response JSON into `LogEntry` objects
4. Marks any unparseable entries as `is_valid=False`
5. If LLM returns fewer entries than input, marks remainder as invalid

**Fallback:** If the LLM call fails entirely, all entries are marked `is_valid=False` with the error message. The pipeline continues — downstream agents will see zero valid logs and short-circuit.

### Detect Agent

**File:** `pipeline/agents/detect.py`
**Model:** Claude Sonnet 4.5 (`claude-sonnet-4-5-20250929`) — $3/MTok
**Temperature:** 0.2

Two-layer threat detection combining rule-based patterns and AI analysis.

**Function:** `run_detect(state: PipelineState) -> dict`

**Behavior:**
1. **Layer 1 (free):** Calls `run_all_rules()` on valid parsed logs
2. **Layer 2 (API):** Sends logs + rule results to Sonnet asking for additional novel threats
3. Merges results: `all_threats = rule_threats + ai_threats`
4. Returns `detection_stats` with breakdown by method

**Fallback:** If AI detection fails, rule-based results are returned alone. No data is lost.

**Returns:**
```python
{
    "threats": list[Threat],
    "detection_stats": {
        "rules_matched": int,
        "ai_detections": int,
        "total_threats": int,
    }
}
```

### Classify Agent

**File:** `pipeline/agents/classify.py`
**Model:** Claude Sonnet 4.5 (`claude-sonnet-4-5-20250929`) — $3/MTok
**Temperature:** 0.1

Risk-scores each threat with MITRE ATT&CK mappings.

**Function:** `run_classify(state: PipelineState) -> dict`

**Behavior:**
1. Formats threats as JSON for the LLM
2. Requests risk level, risk score, MITRE technique/tactic, business impact, affected systems, remediation priority
3. Matches AI classifications back to original threats by `threat_id`
4. Sorts results by `remediation_priority` (1 = highest)

**Fallback:** `_fallback_classify(threat, priority)` assigns `risk="medium"`, `risk_score=5.0` to any threat the AI fails to classify. Ensures all threats get a classification.

### Report Agent

**File:** `pipeline/agents/report.py`
**Model:** Claude Opus 4.6 (`claude-opus-4-6`) — $15/MTok
**Temperature:** 0.3

Generates dual-audience incident reports with action plans.

**Function:** `run_report(state: PipelineState) -> dict`

**Behavior:**
1. Builds context from classified threats, detection stats, and log timeline samples (capped at 50 entries)
2. Requests JSON report with summary, timeline, action plan, recommendations, IOCs, MITRE techniques
3. Computes severity counts from classified threats
4. Returns a complete `IncidentReport` object

**Fallback:** Generates a template report with raw classified threat data and an auto-generated action plan (one step per threat). The `summary` notes that manual review is required.

---

## Pipeline Orchestration

**File:** `pipeline/graph.py`

Uses [LangGraph](https://langchain-ai.github.io/langgraph/) `StateGraph` with conditional edges.

### Graph Structure

```
START
  │
  ▼
[ingest] ──── valid logs? ───┐
  │                          │ No
  │ Yes                      ▼
  ▼                    [empty_report] → END
[detect] ──── threats? ─────┐
  │                         │ No
  │ Yes                     ▼
  ▼                   [clean_report] → END
[classify]
  │
  ▼
[report] → END
```

### Conditional Routing Functions

**`should_detect(state) -> "detect" | "empty_report"`**
Routes to Detect only if at least one `parsed_log` has `is_valid=True`. Otherwise generates an empty report (all logs malformed).

**`should_classify(state) -> "classify" | "clean_report"`**
Routes to Classify only if `threats` list is non-empty. Otherwise generates a clean report (no threats found).

### Short-Circuit Nodes

- **`empty_report_node`** — All logs malformed. Produces report advising review of log sources.
- **`clean_report_node`** — No threats found. Produces report confirming normal activity.

### Entry Points

**`build_pipeline() -> CompiledStateGraph`**
Constructs and compiles the LangGraph pipeline. Called once per invocation.

**`run_pipeline(raw_logs: list[str]) -> PipelineState`**
Main entry point. Initializes state, invokes the graph, records `pipeline_time`.

---

## CLI Reference

**File:** `main.py`

### Usage

```bash
# From file
python main.py sample_logs/brute_force.txt

# From stdin
cat logs.txt | python main.py
```

### Functions

**`cli()`**
Reads logs from file argument or stdin, runs pipeline, prints stats and formatted report.

**`format_report(report: IncidentReport) -> str`**
Formats an `IncidentReport` as plaintext with sections: Executive Summary, Threat Overview, Attack Timeline, Action Plan, IOCs, MITRE Techniques, Strategic Recommendations.

### Output Example

```
======================================================================
  INCIDENT REPORT
======================================================================

EXECUTIVE SUMMARY
----------------------------------------
Brute force SSH attack from 203.0.113.50 detected with 8 failed attempts...

THREAT OVERVIEW
----------------------------------------
  Total threats:  2
  Critical:       1
  High:           1
  Medium:         0
  Low:            0

ACTION PLAN
----------------------------------------
  1. Block IP 203.0.113.50 at firewall [IMMEDIATE] (Security Team)
  2. Reset compromised credentials [1HR] (IT Ops)
  ...
======================================================================
  Generated: 2026-02-10 14:32:01
======================================================================
```

---

## Gradio Dashboard

**File:** `app.py`

### Launch

```bash
python app.py
# Opens at http://localhost:7860
```

### Layout

Four-panel dashboard:

1. **Input Section** — Textarea for pasting logs + dropdown with 4 sample scenarios + "Analyze Threats" button
2. **Stats Bar** — Shows: log count, threat count, invalid count, pipeline time
3. **Threat Detection Panel** — Color-coded threat cards with severity badges and confidence scores
4. **Risk Classification Panel** — 4-column severity grid (critical/high/medium/low counts) + MITRE technique tags
5. **Incident Report** — Full markdown-rendered report

### Event Wiring

| Trigger | Input | Output |
|---------|-------|--------|
| `sample_dropdown.change` | `sample_dropdown` | `log_input` (loads sample text) |
| `analyze_btn.click` | `log_input` | `stats_bar`, `threats_panel`, `classification_panel`, `report_panel` |

### Key Functions

**`analyze_logs(log_text: str) -> tuple[str, str, str, str]`**
Splits input into lines, runs pipeline, formats 4 HTML/markdown outputs.

**`load_sample(sample_name: str) -> str`**
Maps dropdown label to file in `sample_logs/` and returns contents.

**`_severity_color(risk: str) -> str`**
Returns hex color for severity: critical=#dc2626, high=#ea580c, medium=#ca8a04, low=#2563eb, informational=#6b7280.

---

## Error Handling & Fallbacks

Every agent implements graceful degradation:

| Agent | Failure Mode | Fallback Behavior |
|-------|-------------|-------------------|
| **Ingest** | LLM call fails | All entries marked `is_valid=False`, pipeline continues |
| **Ingest** | JSON parse error | Same as above |
| **Detect** | AI detection fails | Returns rule-based results only (printed warning) |
| **Classify** | Classification fails | All threats get `risk=medium`, `risk_score=5.0` |
| **Report** | Report generation fails | Template report with raw data, marked for manual review |

The pipeline **never crashes** — it always produces a result, even if degraded.

---

## Sample Log Formats

### `sample_logs/brute_force.txt`

SSH brute force attack: multiple failed auth attempts from a single IP, followed by a successful login and privilege escalation. Expected: 2+ threats (critical/high).

### `sample_logs/data_exfiltration.txt`

Large outbound SCP transfers to an external IP. Expected: 1+ data exfiltration threat.

### `sample_logs/mixed_threats.txt`

Multi-stage attack: port scanning → brute force → privilege escalation → lateral movement → data exfiltration. Expected: 4+ threats across multiple categories.

### `sample_logs/clean_logs.txt`

Normal operational logs (SSH logins, cron jobs, system updates). Expected: 0 threats. Tests the short-circuit path (detect → clean_report → END).

---

## Testing

```bash
pytest tests/ -v
```

### Test Files

| File | Coverage |
|------|----------|
| `tests/test_ingest.py` | LogEntry model validation, edge cases |
| `tests/test_detect.py` | All 5 rule-based detection patterns, thresholds |
| `tests/test_classify.py` | Fallback classification, model constraints |
| `tests/test_pipeline.py` | Conditional routing, short-circuit paths, state flow |

All tests run **without API calls** — they test models, rules, and routing logic using mocked or synthetic data.

---

## Cost Model

| Agent | Model | Input Cost | Output Cost | Typical Usage |
|-------|-------|-----------|------------|---------------|
| Ingest | Haiku 4.5 | $0.25/MTok | $1.25/MTok | ~500 tokens in, ~1K out |
| Detect | Sonnet 4.5 | $3.00/MTok | $15.00/MTok | ~1K tokens in, ~500 out |
| Classify | Sonnet 4.5 | $3.00/MTok | $15.00/MTok | ~800 tokens in, ~600 out |
| Report | Opus 4.6 | $15.00/MTok | $75.00/MTok | ~1.5K tokens in, ~1K out |

**Cost-saving strategies:**
- Rule-based detection runs first (free, instant)
- Conditional routing skips agents when unnecessary
- Haiku handles high-volume parsing at 12× lower cost than Sonnet
- Opus is only invoked for final report generation (smallest token volume)

Typical cost per analysis: **~$0.01–0.05** depending on log volume and threat count.
