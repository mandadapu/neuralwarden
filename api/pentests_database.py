"""Persistence for pentests: campaigns and findings.

Supports SQLite (local dev) and PostgreSQL (Cloud Run) via api.db layer.
"""

from __future__ import annotations

import json
import logging
import uuid
from datetime import datetime, timezone

from api.db import get_conn, adapt_sql, placeholder, insert_or_ignore, is_postgres

logger = logging.getLogger(__name__)

# ── Severity ordering (lower = more severe) ─────────────────────────

_SEVERITY_ORDER = {"critical": 0, "high": 1, "medium": 2, "low": 3}

# ── Schema initialisation ───────────────────────────────────────────

_CREATE_PENTESTS = """
CREATE TABLE IF NOT EXISTS pentests (
    id TEXT PRIMARY KEY,
    user_email TEXT NOT NULL,
    name TEXT NOT NULL,
    description TEXT DEFAULT '',
    vendor TEXT DEFAULT 'manual',
    vendor_id TEXT DEFAULT '',
    status TEXT DEFAULT 'planned',
    severity TEXT DEFAULT 'medium',
    start_date TEXT,
    end_date TEXT,
    scope TEXT DEFAULT '',
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL
)
"""

_CREATE_PENTEST_FINDINGS = """
CREATE TABLE IF NOT EXISTS pentest_findings (
    id TEXT PRIMARY KEY,
    pentest_id TEXT NOT NULL,
    title TEXT NOT NULL,
    description TEXT DEFAULT '',
    severity TEXT DEFAULT 'medium',
    cvss_score REAL,
    status TEXT DEFAULT 'open',
    category TEXT DEFAULT '',
    affected_url TEXT DEFAULT '',
    remediation_notes TEXT DEFAULT '',
    evidence TEXT DEFAULT '',
    discovered_at TEXT NOT NULL,
    resolved_at TEXT,
    cwe_id TEXT DEFAULT '',
    cve_id TEXT DEFAULT '',
    request_data TEXT DEFAULT '',
    response_data TEXT DEFAULT '',
    validation_status TEXT DEFAULT 'unverified',
    validation_notes TEXT DEFAULT '',
    check_rule_code TEXT DEFAULT '',
    FOREIGN KEY (pentest_id) REFERENCES pentests(id)
)
"""

_CREATE_PENTEST_CHECKS = """
CREATE TABLE IF NOT EXISTS pentest_checks (
    id TEXT PRIMARY KEY,
    rule_code TEXT NOT NULL UNIQUE,
    title TEXT NOT NULL,
    description TEXT DEFAULT '',
    group_name TEXT DEFAULT 'owasp',
    subchecks_json TEXT DEFAULT '[]',
    severity_default TEXT DEFAULT 'high',
    cwe_ids TEXT DEFAULT ''
)
"""


def init_pentest_tables() -> None:
    """Create pentest tables if they don't exist."""
    conn = get_conn()
    try:
        conn.execute(_CREATE_PENTESTS)
        conn.execute(_CREATE_PENTEST_FINDINGS)
        conn.execute(_CREATE_PENTEST_CHECKS)
        # Indexes for frequently queried columns
        conn.execute("CREATE INDEX IF NOT EXISTS idx_pentests_user ON pentests(user_email)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_pentest_findings_pentest ON pentest_findings(pentest_id)")
        # Migrate existing pentest_findings tables missing new columns
        for migration in [
            "ALTER TABLE pentest_findings ADD COLUMN cwe_id TEXT DEFAULT ''",
            "ALTER TABLE pentest_findings ADD COLUMN cve_id TEXT DEFAULT ''",
            "ALTER TABLE pentest_findings ADD COLUMN request_data TEXT DEFAULT ''",
            "ALTER TABLE pentest_findings ADD COLUMN response_data TEXT DEFAULT ''",
            "ALTER TABLE pentest_findings ADD COLUMN validation_status TEXT DEFAULT 'unverified'",
            "ALTER TABLE pentest_findings ADD COLUMN validation_notes TEXT DEFAULT ''",
            "ALTER TABLE pentest_findings ADD COLUMN check_rule_code TEXT DEFAULT ''",
        ]:
            try:
                if is_postgres():
                    conn.execute("SAVEPOINT pf_migration")
                conn.execute(migration)
                if is_postgres():
                    conn.execute("RELEASE SAVEPOINT pf_migration")
            except Exception:
                if is_postgres():
                    conn.execute("ROLLBACK TO SAVEPOINT pf_migration")
                # column already exists — safe to ignore
        conn.commit()
    finally:
        conn.close()


# ── Pentests CRUD ────────────────────────────────────────────────────


def create_pentest(
    user_email: str,
    name: str,
    description: str = "",
    vendor: str = "manual",
    vendor_id: str = "",
    status: str = "planned",
    severity: str = "medium",
    start_date: str | None = None,
    end_date: str | None = None,
    scope: str = "",
) -> str:
    """Create a pentest and return its ID."""
    pentest_id = str(uuid.uuid4())
    now = datetime.now(timezone.utc).isoformat()
    p = placeholder
    conn = get_conn()
    try:
        conn.execute(
            f"""INSERT INTO pentests
               (id, user_email, name, description, vendor, vendor_id,
                status, severity, start_date, end_date, scope,
                created_at, updated_at)
               VALUES ({p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p})""",
            (
                pentest_id,
                user_email,
                name,
                description,
                vendor,
                vendor_id,
                status,
                severity,
                start_date,
                end_date,
                scope,
                now,
                now,
            ),
        )
        conn.commit()
        logger.info("audit: pentest created id=%s user=%s name=%s", pentest_id, user_email, name)
        return pentest_id
    finally:
        conn.close()


def list_pentests(user_email: str) -> list[dict]:
    """List all pentests for a user, newest first."""
    conn = get_conn()
    try:
        rows = conn.execute(
            adapt_sql("SELECT * FROM pentests WHERE user_email = ? ORDER BY created_at DESC"),
            (user_email,),
        ).fetchall()
        return [dict(row) for row in rows]
    finally:
        conn.close()


def get_pentest(pentest_id: str) -> dict | None:
    """Get a pentest by ID, or None."""
    conn = get_conn()
    try:
        row = conn.execute(
            adapt_sql("SELECT * FROM pentests WHERE id = ?"), (pentest_id,)
        ).fetchone()
        return dict(row) if row else None
    finally:
        conn.close()


_ALLOWED_PENTEST_FIELDS = {
    "name",
    "description",
    "vendor",
    "vendor_id",
    "status",
    "severity",
    "start_date",
    "end_date",
    "scope",
}


def update_pentest(pentest_id: str, **fields) -> None:
    """Update allowed fields on a pentest."""
    updates = {k: v for k, v in fields.items() if k in _ALLOWED_PENTEST_FIELDS}
    if not updates:
        return
    updates["updated_at"] = datetime.now(timezone.utc).isoformat()
    p = placeholder
    set_clause = ", ".join(f"{k} = {p}" for k in updates)
    values = list(updates.values()) + [pentest_id]
    conn = get_conn()
    try:
        conn.execute(
            f"UPDATE pentests SET {set_clause} WHERE id = {p}",
            values,
        )
        conn.commit()
        logger.info("audit: pentest updated id=%s fields=%s", pentest_id, [k for k in updates if k != "updated_at"])
    finally:
        conn.close()


def delete_pentest(pentest_id: str) -> None:
    """Delete a pentest and cascade-delete its findings."""
    conn = get_conn()
    try:
        conn.execute(adapt_sql("DELETE FROM pentest_findings WHERE pentest_id = ?"), (pentest_id,))
        conn.execute(adapt_sql("DELETE FROM pentests WHERE id = ?"), (pentest_id,))
        conn.commit()
        logger.info("audit: pentest deleted id=%s", pentest_id)
    finally:
        conn.close()


# ── Findings CRUD ────────────────────────────────────────────────────


def create_finding(
    pentest_id: str,
    title: str,
    description: str = "",
    severity: str = "medium",
    cvss_score: float | None = None,
    status: str = "open",
    category: str = "",
    affected_url: str = "",
    remediation_notes: str = "",
    evidence: str = "",
    discovered_at: str | None = None,
    cwe_id: str = "",
    cve_id: str = "",
    request_data: str = "",
    response_data: str = "",
    validation_status: str = "unverified",
    validation_notes: str = "",
    check_rule_code: str = "",
) -> str:
    """Create a finding and return its ID."""
    finding_id = str(uuid.uuid4())
    now = datetime.now(timezone.utc).isoformat()
    p = placeholder
    conn = get_conn()
    try:
        conn.execute(
            f"""INSERT INTO pentest_findings
               (id, pentest_id, title, description, severity, cvss_score,
                status, category, affected_url, remediation_notes, evidence,
                discovered_at, resolved_at,
                cwe_id, cve_id, request_data, response_data,
                validation_status, validation_notes, check_rule_code)
               VALUES ({p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p},
                       {p}, {p}, {p}, {p}, {p}, {p}, {p})""",
            (
                finding_id,
                pentest_id,
                title,
                description,
                severity,
                cvss_score,
                status,
                category,
                affected_url,
                remediation_notes,
                evidence,
                discovered_at or now,
                None,
                cwe_id,
                cve_id,
                request_data,
                response_data,
                validation_status,
                validation_notes,
                check_rule_code,
            ),
        )
        conn.commit()
        logger.info("audit: finding created id=%s pentest=%s severity=%s title=%s", finding_id, pentest_id, severity, title)
        return finding_id
    finally:
        conn.close()


def list_findings(
    pentest_id: str, status: str = "", severity: str = ""
) -> list[dict]:
    """List findings for a pentest, sorted by severity then discovered_at."""
    p = placeholder
    conn = get_conn()
    try:
        query = f"SELECT * FROM pentest_findings WHERE pentest_id = {p}"
        params: list = [pentest_id]
        if status:
            query += f" AND status = {p}"
            params.append(status)
        if severity:
            query += f" AND severity = {p}"
            params.append(severity)
        rows = conn.execute(query, params).fetchall()
        results = [dict(row) for row in rows]
        results.sort(
            key=lambda r: (
                _SEVERITY_ORDER.get(r["severity"], 99),
                r["discovered_at"],
            )
        )
        return results
    finally:
        conn.close()


def get_finding(finding_id: str) -> dict | None:
    """Get a single finding by ID."""
    conn = get_conn()
    try:
        row = conn.execute(
            adapt_sql("SELECT * FROM pentest_findings WHERE id = ?"), (finding_id,)
        ).fetchone()
        return dict(row) if row else None
    finally:
        conn.close()


_ALLOWED_FINDING_FIELDS = {
    "title",
    "description",
    "severity",
    "cvss_score",
    "status",
    "category",
    "affected_url",
    "remediation_notes",
    "evidence",
    "resolved_at",
    "cwe_id",
    "cve_id",
    "request_data",
    "response_data",
    "validation_status",
    "validation_notes",
    "check_rule_code",
}


def update_finding(finding_id: str, **fields) -> None:
    """Update allowed fields on a finding."""
    updates = {k: v for k, v in fields.items() if k in _ALLOWED_FINDING_FIELDS}
    if not updates:
        return
    # Auto-set resolved_at when status changes to resolved
    if updates.get("status") == "resolved" and "resolved_at" not in updates:
        updates["resolved_at"] = datetime.now(timezone.utc).isoformat()
    p = placeholder
    set_clause = ", ".join(f"{k} = {p}" for k in updates)
    values = list(updates.values()) + [finding_id]
    conn = get_conn()
    try:
        conn.execute(
            f"UPDATE pentest_findings SET {set_clause} WHERE id = {p}",
            values,
        )
        conn.commit()
        logger.info("audit: finding updated id=%s fields=%s", finding_id, list(updates.keys()))
    finally:
        conn.close()


def get_finding_counts(pentest_id: str) -> dict:
    """Count findings by severity for a pentest."""
    conn = get_conn()
    try:
        rows = conn.execute(
            adapt_sql(
                """SELECT severity, COUNT(*) as cnt
                   FROM pentest_findings
                   WHERE pentest_id = ?
                   GROUP BY severity"""
            ),
            (pentest_id,),
        ).fetchall()
        counts = {r["severity"]: r["cnt"] for r in rows}
        return {
            "critical": counts.get("critical", 0),
            "high": counts.get("high", 0),
            "medium": counts.get("medium", 0),
            "low": counts.get("low", 0),
            "total": sum(counts.values()),
        }
    finally:
        conn.close()


def bulk_import_findings(pentest_id: str, findings: list[dict]) -> int:
    """Bulk import findings for a pentest. Returns the number inserted."""
    now = datetime.now(timezone.utc).isoformat()
    p = placeholder
    conn = get_conn()
    try:
        count = 0
        for f in findings:
            conn.execute(
                f"""INSERT INTO pentest_findings
                   (id, pentest_id, title, description, severity, cvss_score,
                    status, category, affected_url, remediation_notes, evidence,
                    discovered_at, resolved_at,
                    cwe_id, cve_id, request_data, response_data,
                    validation_status, validation_notes, check_rule_code)
                   VALUES ({p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p}, {p},
                           {p}, {p}, {p}, {p}, {p}, {p}, {p})""",
                (
                    str(uuid.uuid4()),
                    pentest_id,
                    f.get("title", ""),
                    f.get("description", ""),
                    f.get("severity", "medium"),
                    f.get("cvss_score"),
                    f.get("status", "open"),
                    f.get("category", ""),
                    f.get("affected_url", ""),
                    f.get("remediation_notes", ""),
                    f.get("evidence", ""),
                    f.get("discovered_at", now),
                    f.get("resolved_at"),
                    f.get("cwe_id", ""),
                    f.get("cve_id", ""),
                    f.get("request_data", ""),
                    f.get("response_data", ""),
                    f.get("validation_status", "unverified"),
                    f.get("validation_notes", ""),
                    f.get("check_rule_code", ""),
                ),
            )
            count += 1
        conn.commit()
        logger.info("audit: findings bulk imported pentest=%s count=%d", pentest_id, count)
        return count
    finally:
        conn.close()


# ── Pentest Checks ──────────────────────────────────────────────────

_CHECKS_SEED = [
    {
        "rule_code": "bola_idor",
        "title": "Broken Access Control (BOLA/IDOR)",
        "description": "Cross-tenant data leaks, authorization issues, IDOR, improper access control.",
        "group_name": "owasp",
        "severity_default": "critical",
        "cwe_ids": "CWE-639,CWE-284",
        "subchecks": [
            "Cross-tenant data access via direct object reference",
            "Horizontal privilege escalation between user accounts",
            "Missing object-level authorization checks",
            "Predictable resource IDs enabling enumeration",
            "Insecure direct object references in API endpoints",
        ],
    },
    {
        "rule_code": "broken_access",
        "title": "Privilege Escalation & Admin Access",
        "description": "Vertical privilege escalation, unauthorized admin functions, role bypass.",
        "group_name": "owasp",
        "severity_default": "critical",
        "cwe_ids": "CWE-269,CWE-285",
        "subchecks": [
            "Vertical privilege escalation to admin roles",
            "Unauthorized access to admin-only functions",
            "Role-based access control bypass",
            "Function-level access control missing",
            "Mass assignment leading to privilege escalation",
        ],
    },
    {
        "rule_code": "sql_injection",
        "title": "SQL & Database Injection",
        "description": "SQL injection, NoSQL injection, XPath injection, LDAP injection.",
        "group_name": "owasp",
        "severity_default": "critical",
        "cwe_ids": "CWE-89,CWE-943",
        "subchecks": [
            "Classic SQL injection (UNION, error-based, blind)",
            "NoSQL injection (MongoDB operator injection)",
            "Second-order SQL injection via stored data",
            "XPath/LDAP injection in directory lookups",
            "ORM injection through query builder abuse",
        ],
    },
    {
        "rule_code": "command_injection",
        "title": "Code & Command Injection",
        "description": "Remote code execution, OS command injection, expression language injection.",
        "group_name": "owasp",
        "severity_default": "critical",
        "cwe_ids": "CWE-78,CWE-94",
        "subchecks": [
            "OS command injection via unsanitized input",
            "Remote code execution through deserialization",
            "Expression language injection (EL, OGNL, SpEL)",
            "Server-side code injection via eval/exec",
            "Code injection through file inclusion",
        ],
    },
    {
        "rule_code": "xss",
        "title": "Client-Side Attacks (XSS/CSRF)",
        "description": "Stored & reflected XSS, CSRF, open redirects, web cache poisoning.",
        "group_name": "owasp",
        "severity_default": "high",
        "cwe_ids": "CWE-79,CWE-352",
        "subchecks": [
            "Stored XSS in user-generated content",
            "Reflected XSS via URL parameters",
            "DOM-based XSS through client-side routing",
            "Cross-site request forgery on state-changing actions",
            "Open redirects enabling phishing attacks",
            "Web cache poisoning via host header injection",
        ],
    },
    {
        "rule_code": "auth_failures",
        "title": "Authentication & Session Management",
        "description": "Brute force, credential stuffing, cookie integrity, session fixation.",
        "group_name": "owasp",
        "severity_default": "high",
        "cwe_ids": "CWE-287,CWE-384",
        "subchecks": [
            "Brute force attacks on login endpoints",
            "Credential stuffing with known breached passwords",
            "Session fixation and session hijacking",
            "Insecure cookie attributes (missing Secure/HttpOnly)",
            "Missing rate limiting on authentication endpoints",
            "JWT signature bypass or algorithm confusion",
        ],
    },
    {
        "rule_code": "ssrf",
        "title": "Server-Side Request Forgery (SSRF)",
        "description": "Internal resource access, cloud metadata theft, external system manipulation.",
        "group_name": "owasp",
        "severity_default": "high",
        "cwe_ids": "CWE-918",
        "subchecks": [
            "SSRF to cloud metadata endpoint (169.254.169.254)",
            "Internal network scanning via SSRF",
            "SSRF through URL parsers and redirects",
            "Blind SSRF with out-of-band detection",
            "SSRF via file:// and gopher:// protocols",
        ],
    },
    {
        "rule_code": "llm_injection",
        "title": "LLM & Prompt Injection",
        "description": "Prompt injection, jailbreaking, system context leakage, data exfiltration.",
        "group_name": "advanced",
        "severity_default": "high",
        "cwe_ids": "CWE-77",
        "subchecks": [
            "Direct prompt injection overriding system instructions",
            "Indirect prompt injection via user-supplied data",
            "System prompt extraction through jailbreak techniques",
            "Data exfiltration through crafted prompts",
            "Prompt injection via multimodal inputs (images, files)",
        ],
    },
    {
        "rule_code": "business_logic",
        "title": "Business Logic & Validation",
        "description": "Workflow bypasses, input validation errors, payment step skipping.",
        "group_name": "advanced",
        "severity_default": "high",
        "cwe_ids": "CWE-840",
        "subchecks": [
            "Multi-step workflow bypass (skipping payment steps)",
            "Price manipulation via client-side parameter tampering",
            "Race conditions in state-changing operations",
            "Abuse of referral/reward systems",
            "Input validation bypass through encoding tricks",
        ],
    },
    {
        "rule_code": "deserialization",
        "title": "Insecure Deserialization & SSTI",
        "description": "Unsafe object handling, server-side template injection, gadget chains.",
        "group_name": "advanced",
        "severity_default": "critical",
        "cwe_ids": "CWE-502,CWE-1336",
        "subchecks": [
            "Java/Python/PHP deserialization leading to RCE",
            "Server-side template injection (Jinja2, Twig, Freemarker)",
            "XML external entity (XXE) injection",
            "YAML deserialization attacks",
            "Gadget chain exploitation in common libraries",
        ],
    },
    {
        "rule_code": "files_misconfig",
        "title": "Files & Misconfigurations",
        "description": "LFI, unrestricted uploads, directory listing, error leakage, path traversal.",
        "group_name": "advanced",
        "severity_default": "medium",
        "cwe_ids": "CWE-22,CWE-434",
        "subchecks": [
            "Local file inclusion (LFI) via path traversal",
            "Unrestricted file upload with executable content",
            "Directory listing exposing sensitive files",
            "Verbose error messages leaking stack traces",
            "Path traversal in file download endpoints",
        ],
    },
    {
        "rule_code": "secrets_crypto",
        "title": "Secrets & Cryptography",
        "description": "Hardcoded credentials, weak crypto, JWT bypass, sensitive data exposure.",
        "group_name": "hardening",
        "severity_default": "high",
        "cwe_ids": "CWE-798,CWE-327",
        "subchecks": [
            "Hardcoded API keys and credentials in source code",
            "Weak cryptographic algorithms (MD5, SHA1, DES)",
            "JWT none-algorithm or weak-secret bypass",
            "Sensitive data in URL parameters or logs",
            "Missing encryption for data at rest or in transit",
        ],
    },
    {
        "rule_code": "hardening",
        "title": "Hardening & Defensive Controls",
        "description": "GraphQL gaps, CORS misconfig, TLS issues, security headers, rate limiting.",
        "group_name": "hardening",
        "severity_default": "medium",
        "cwe_ids": "CWE-16,CWE-693",
        "subchecks": [
            "GraphQL introspection enabled in production",
            "Overly permissive CORS configuration",
            "Missing or weak TLS configuration",
            "Missing security headers (CSP, HSTS, X-Frame-Options)",
            "Absent rate limiting on sensitive endpoints",
            "Environment variables or debug info exposed",
        ],
    },
]


def seed_pentest_checks() -> None:
    """Insert the 13 check categories if they don't already exist."""
    conn = get_conn()
    try:
        p = placeholder
        columns = ["id", "rule_code", "title", "description", "group_name",
                    "subchecks_json", "severity_default", "cwe_ids"]
        placeholders_str = ", ".join([p] * len(columns))
        sql = insert_or_ignore("pentest_checks", columns, placeholders_str)
        for check in _CHECKS_SEED:
            check_id = str(uuid.uuid4())
            subchecks_json = json.dumps(check["subchecks"])
            conn.execute(
                sql,
                (
                    check_id,
                    check["rule_code"],
                    check["title"],
                    check["description"],
                    check["group_name"],
                    subchecks_json,
                    check["severity_default"],
                    check["cwe_ids"],
                ),
            )
        conn.commit()
    finally:
        conn.close()


def list_pentest_checks(group: str = "") -> list[dict]:
    """List all pentest checks, optionally filtered by group_name."""
    p = placeholder
    conn = get_conn()
    try:
        if group:
            rows = conn.execute(
                f"SELECT * FROM pentest_checks WHERE group_name = {p} ORDER BY rule_code",
                (group,),
            ).fetchall()
        else:
            rows = conn.execute(
                "SELECT * FROM pentest_checks ORDER BY group_name, rule_code"
            ).fetchall()
        results = []
        for row in rows:
            d = dict(row)
            d["subchecks"] = json.loads(d.pop("subchecks_json", "[]"))
            results.append(d)
        return results
    finally:
        conn.close()
